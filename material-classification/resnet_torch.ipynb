{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_wh = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 9번 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"9\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkT6iCTFui4s"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import copy\n",
    "import sys, time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/home/j-j9s006\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VHTiM4aMdin"
   },
   "source": [
    "# Data 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### K-FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1694419880480,
     "user": {
      "displayName": "DADADA1",
      "userId": "14100237047563402184"
     },
     "user_tz": -540
    },
    "id": "Hh_Fbc-d9zRe",
    "outputId": "7abc1705-e03d-4e48-f835-0ff7d3271a4d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(base_directory, \"material-classification\", \"k-fashion-label-material.csv\"), encoding='cp949')\n",
    "df = df[['file', 'type_id']]\n",
    "\n",
    "df.dropna(subset=['type_id'], axis=0, how='any' , inplace=True)\n",
    "df['type_id'] = df['type_id'].astype(int)\n",
    "\n",
    "df['Filepath'] = base_directory + \"/datasets/k-fashion/\"+ df['file']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deep Fashion In shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.read_csv(os.path.join(base_directory,\"material-classification\", \"deep-inshop-label-material.csv\"), encoding='cp949')\n",
    "add_df = add_df[['image_id', 'type_id']]\n",
    "\n",
    "add_df.dropna(subset=['type_id'], axis=0, how='any' , inplace=True)\n",
    "add_df['type_id'] = add_df['type_id'].astype(int)\n",
    "add_df['Filepath'] = base_directory + \"/datasets/deep-fashion/inshop/segment-results/\"+ add_df['image_id']+\".png\"\n",
    "add_df = add_df.rename(columns={'image_id': 'file'})\n",
    "add_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, add_df], ignore_index=True)\n",
    "\n",
    "df.dropna(subset=['type_id'], axis=0, how='any' , inplace=True)\n",
    "\n",
    "\n",
    "# type_id 를 str로 수정\n",
    "df['type_id'] = df['type_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data 정제 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['type_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type id별로 몇개의 데이터가 있는지 확인\n",
    "print(df['type_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터셋 총 개수 및 label 종류 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1694419880480,
     "user": {
      "displayName": "DADADA1",
      "userId": "14100237047563402184"
     },
     "user_tz": -540
    },
    "id": "SK8MWeEd_5nf",
    "outputId": "196a13a9-a409-4a99-f7e7-0ef6af657415"
   },
   "outputs": [],
   "source": [
    "labels = df['type_id'].values.tolist()\n",
    "\n",
    "label_list=[]\n",
    "for i in labels:\n",
    "    if i not in label_list:\n",
    "        label_list.append(i)\n",
    "\n",
    "print('The number of pictures:', df.shape[0])\n",
    "print('The number of labels:', len(label_list))\n",
    "print('Labels:', label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 85900,
     "status": "ok",
     "timestamp": 1694420099592,
     "user": {
      "displayName": "DADADA1",
      "userId": "14100237047563402184"
     },
     "user_tz": -540
    },
    "id": "P-8SYlf6ANsl",
    "outputId": "b984ccfb-8e09-4929-8ba5-6323e0e4122d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=10, ncols=5, figsize=(8, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df.Filepath[i]))\n",
    "    ax.set_title(df.type_id[i], fontsize = 12)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test valid 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1694420105265,
     "user": {
      "displayName": "DADADA1",
      "userId": "14100237047563402184"
     },
     "user_tz": -540
    },
    "id": "kH1s23rmGJbp",
    "outputId": "271d0fc9-75fc-4555-e56c-ba6c3e392384"
   },
   "outputs": [],
   "source": [
    "# train, test set으로 split(9대 1)\n",
    "train_df,test_df = train_test_split(df, test_size=0.1,random_state=1234)\n",
    "\n",
    "\n",
    "# train_df를 9대 1로 split(train과 valid로)\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYTORCH에서 쓰는 방식으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 변환 함수\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_wh, image_wh)),\n",
    "    transforms.ToTensor(),\n",
    "    # 필요한 경우 추가적인 변환 (예: Normalize, RandomHorizontalFlip 등) 추가\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 전체 이미지에 대해 동일한 환경으로 맞춰줌\n",
    "])\n",
    "\n",
    "def load_paths_from_dataframe(df):\n",
    "    image_paths = df['Filepath'].tolist()\n",
    "    labels = df['type_id'].tolist()\n",
    "    return image_paths, labels\n",
    "\n",
    "# sample_image_path = \"/home/j-j9s006/datasets/deep-fashion/inshop/segment-results/SE0000001.png\"\n",
    "# image = Image.open(sample_image_path)\n",
    "# transformed_image = transform(image)\n",
    "# print(transformed_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "X_train, y_train = load_paths_from_dataframe(train_df)\n",
    "X_test, y_test = load_paths_from_dataframe(test_df)\n",
    "X_valid, y_valid = load_paths_from_dataframe(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1583506858941,
     "user": {
      "displayName": "안영빈",
      "photoUrl": "",
      "userId": "11009136941831442800"
     },
     "user_tz": -540
    },
    "id": "o8pTYbRASpL9",
    "outputId": "9cc96353-f5c1-4417-ceb7-696e6fb71e79"
   },
   "outputs": [],
   "source": [
    "class compare_train_test_valid_dataset():\n",
    "    def __init__(self,li):\n",
    "        self.li = li\n",
    "        self.len_train = len(li[0])\n",
    "        self.len_valid = len(li[1])\n",
    "        self.len_test = len(li[2])\n",
    "    def __call__(self):\n",
    "        #draw plt\n",
    "        label = ['train', 'valid','test']\n",
    "        data = [self.len_train,self.len_valid,self.len_test]\n",
    "        plt.rcParams[\"font.size\"] = 12\n",
    "        plt.figure(figsize=(12,8))\n",
    "\n",
    "        x = np.arange(len(label))\n",
    "\n",
    "        plt.bar(x, [self.len_train,self.len_valid,self.len_test], label='data', width=0.3, color='#FFFF00')\n",
    "        plt.legend()\n",
    "        plt.xticks(x, label)\n",
    "        plt.ylabel('Number of data')\n",
    "        plt.title('Compare DATASETS')\n",
    "        plt.show()\n",
    "\n",
    "show =compare_train_test_valid_dataset([X_train,X_valid,X_test])\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYpehu5WM4pk"
   },
   "source": [
    "# Aug Comporse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrceYpiAlnzj"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # 이 줄을 추가합니다.\n",
    "    transforms.RandomCrop(224, padding=3),  # 크기를 224로 수정합니다.\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # 이 줄을 추가합니다.\n",
    "    transforms.CenterCrop(224),  # 크기를 224로 수정합니다.\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFWhq9JTNEqM"
   },
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCwOxQprm0O6"
   },
   "outputs": [],
   "source": [
    "def rgba_to_rgb(image, background_color=(255, 255, 255)):\n",
    "    if image.mode == 'RGBA':\n",
    "        bg = Image.new('RGB', image.size, background_color)\n",
    "        bg.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "        return bg\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "class clothes_Dataset(Dataset):\n",
    "    def __init__(self, image_paths, y, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_list = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = rgba_to_rgb(img)  # 이미지를 RGB로 변환\n",
    "        label = int(self.label_list[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train, y_train = load_paths_from_dataframe(train_df)\n",
    "image_paths_test, y_test = load_paths_from_dataframe(test_df)\n",
    "image_paths_valid, y_valid = load_paths_from_dataframe(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hX9FPZ2uontI"
   },
   "outputs": [],
   "source": [
    "Trainset = clothes_Dataset(image_paths=image_paths_train, y=y_train, transform=train_transform)\n",
    "Valset = clothes_Dataset(image_paths=image_paths_valid, y=y_valid, transform=test_transform)\n",
    "Testset = clothes_Dataset(image_paths=image_paths_test, y=y_test, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjJ7ULFmsIWA"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(Trainset, batch_size=32, shuffle=True, num_workers=1)\n",
    "Valloader = DataLoader(Valset, batch_size=32, shuffle=True, num_workers=1)\n",
    "testloader = DataLoader(Testset, batch_size=32, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hg16JUVfNUP0"
   },
   "source": [
    "# Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision에서 제공하는 ResNet50 불러오기\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# 클래스의 수를 변경하려면 마지막 Fully Connected Layer를 변경해야 합니다.\n",
    "num_classes = len(label_list)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# 모델을 GPU로 옮기기\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2qWF0QObHUW"
   },
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(current, total, loss, acc, length=50):\n",
    "    progress = current / total\n",
    "    arrow = '=' * int(round(progress * length) - 1) + '>'\n",
    "    spaces = ' ' * (length - len(arrow))\n",
    "\n",
    "    sys.stdout.write('\\r[%s%s] %d/%d | Loss: %.3f | Accuracy: %.2f%%' % (arrow, spaces, current, total, loss, acc*100))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# train 함수\n",
    "def train(epoch, model, trainloader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        acc = correct / total\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), loss=train_loss/(batch_idx+1), acc=acc)\n",
    "\n",
    "    print(f\"\\nTrain Epoch: {epoch}, Loss: {train_loss/len(trainloader)}, Accuracy: {100.*correct/total:.2f}%\")\n",
    "\n",
    "# validate 함수\n",
    "def validate(epoch, model, valloader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            acc = correct / total\n",
    "\n",
    "            progress_bar(batch_idx, len(valloader), loss=val_loss/(batch_idx+1), acc=acc)\n",
    "\n",
    "    print(f\"\\nValidation Epoch: {epoch}, Loss: {val_loss/len(valloader)}, Accuracy: {100.*correct/total:.2f}%\")\n",
    "\n",
    "# test 함수\n",
    "def test(model, dataframe, testloader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.long())\n",
    "\n",
    "            test_loss += loss.data.cpu().numpy()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            acc = correct / total\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), loss=test_loss/(batch_idx+1), acc=acc)\n",
    "\n",
    "            # 예측 결과와 원본 이미지를 시각화합니다.\n",
    "            for local_idx, (pred, actual) in enumerate(zip(predicted, targets)):\n",
    "                global_idx = batch_idx * testloader.batch_size + local_idx\n",
    "                original_image_path = dataframe.iloc[global_idx]['Filepath']\n",
    "                print(f\"\\nDataframe Path: {original_image_path}, Actual Label: {actual.cpu().item()}\")\n",
    "                img = Image.open(original_image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Predicted Label: {cloth_label[pred.cpu().item()]} ({pred.cpu().item()})\")\n",
    "                plt.show()\n",
    "\n",
    "        epoch_loss = test_loss / len(testloader)\n",
    "        epoch_acc = correct / total\n",
    "        print('\\ntest | Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch, model, trainloader)\n",
    "    validate(epoch, model, Valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9725,
     "status": "ok",
     "timestamp": 1583510686554,
     "user": {
      "displayName": "안영빈",
      "photoUrl": "",
      "userId": "11009136941831442800"
     },
     "user_tz": -540
    },
    "id": "SCHkuD0237k-",
    "outputId": "c0ff48c5-a836-4c7f-afaa-39ffe3b17f19"
   },
   "outputs": [],
   "source": [
    "# Label 정보\n",
    "cloth_label = {\n",
    "    0: \"Fur\",\n",
    "    1: \"Cotton/Polyester\",\n",
    "    2: \"Knit\",\n",
    "    3: \"Denim\",\n",
    "    4: \"Chiffon\",\n",
    "    5: \"Padding\",\n",
    "    6: \"Tweed\",\n",
    "    7: \"Fleece\",\n",
    "    8: \"Leather\",\n",
    "    9: \"Corduroy\",\n",
    "}\n",
    "\n",
    "# 아래 코드를 통해 테스트 진행\n",
    "predictions = test(model, df, testloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO38EpoBDH1Lr5a/GKirmkq",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "resnet_torch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "virtual-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
